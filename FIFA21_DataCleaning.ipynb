{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a162e0",
   "metadata": {},
   "source": [
    "![Data Cleaning using Pandas](Data-Cleaning-Using-Pandas.jpg)\n",
    "\n",
    "# Project: Data Cleaning\n",
    "Welcome to my data cleaning project, where I will be working with the FIFA 2021 dataset obtained from Kaggle. <br>\n",
    "You can find the Data set here: \n",
    "<a href=\"https://www.kaggle.com/datasets/yagunnersya/fifa-21-messy-raw-dataset-for-cleaning-exploring?select=fifa21_raw_data.csv%E2%80%8B\">FIFA 2021 Dataset.</a><br>\n",
    "In this project, my main focus is on cleaning and preparing the raw data for analysis.\n",
    "\n",
    "**Links to negivate through the project:**\n",
    "- [Need for data Cleaning](#need)\n",
    "- [Aim of the project](#aim)\n",
    "- [Making a copy of data frame](#copy)\n",
    "- [Checkng for null vakues](#null)\n",
    "- [Removing special characters](#special)\n",
    "- [Coverting numbers with K and M into simple form](#k-m_to_int)\n",
    "- [Label encoding](#label)\n",
    "- [Changing into right Data type](#Datatype)\n",
    "- [Converting pounds into kg](#Pounds_to_kg)\n",
    "- [Using the copyied data frame](#use_copy)\n",
    "- [Converting Feet-inch into cm](#feet-inch_to_cm)\n",
    "- [Coverting to Datetime data type](#Datetime)\n",
    "- [Extract date, month & year](#extract)\n",
    "- [saving cleaned data](#save)\n",
    "- [Closing of project](#close)\n",
    "- [Acknowledgement](#ack)\n",
    "\n",
    "## Need for Data Cleaning: \n",
    "<a id='Need'></a>\n",
    "Data cleaning plays a crucial role in ensuring the accuracy and quality of the data we work with. By addressing missing values, inconsistencies, and errors within the dataset, we can trust the results of our analysis and make better and        informed decisions.\n",
    "\n",
    "## Aim:\n",
    "<a id='aim'></a>\n",
    "By the end of this project, I will have transformed the raw data into a clean and reliable dataset that can be used for further analysis. I invite you to join me on this journey of data cleaning as we dive into the FIFA 2021 dataset and uncover its hidden insights. So, let's get started and explore the fascinating world of data cleaning in the context of the FIFA 2021 dataset. Together, we will ensure the data is accurate, consistent, and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe6aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file using read_csv method of pandas liabrary\n",
    "import pandas as pd\n",
    "raw_df = pd.read_csv('fifa21_raw_data_v2.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0440651e",
   "metadata": {},
   "source": [
    "## Creating a copy of the dataset\n",
    "<a id='copy'></a>\n",
    "It is always a good practice to make a copy of your dataset for backup if something gets wrong with the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2277204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a copy of the dataframe\n",
    "copy_df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2dc016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18979 entries, 0 to 18978\n",
      "Data columns (total 77 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ID                18979 non-null  int64 \n",
      " 1   Name              18979 non-null  object\n",
      " 2   LongName          18979 non-null  object\n",
      " 3   photoUrl          18979 non-null  object\n",
      " 4   playerUrl         18979 non-null  object\n",
      " 5   Nationality       18979 non-null  object\n",
      " 6   Age               18979 non-null  int64 \n",
      " 7   ↓OVA              18979 non-null  int64 \n",
      " 8   POT               18979 non-null  int64 \n",
      " 9   Club              18979 non-null  object\n",
      " 10  Contract          18979 non-null  object\n",
      " 11  Positions         18979 non-null  object\n",
      " 12  Height            18979 non-null  object\n",
      " 13  Weight            18979 non-null  object\n",
      " 14  Preferred Foot    18979 non-null  object\n",
      " 15  BOV               18979 non-null  int64 \n",
      " 16  Best Position     18979 non-null  object\n",
      " 17  Joined            18979 non-null  object\n",
      " 18  Loan Date End     1013 non-null   object\n",
      " 19  Value             18979 non-null  object\n",
      " 20  Wage              18979 non-null  object\n",
      " 21  Release Clause    18979 non-null  object\n",
      " 22  Attacking         18979 non-null  int64 \n",
      " 23  Crossing          18979 non-null  int64 \n",
      " 24  Finishing         18979 non-null  int64 \n",
      " 25  Heading Accuracy  18979 non-null  int64 \n",
      " 26  Short Passing     18979 non-null  int64 \n",
      " 27  Volleys           18979 non-null  int64 \n",
      " 28  Skill             18979 non-null  int64 \n",
      " 29  Dribbling         18979 non-null  int64 \n",
      " 30  Curve             18979 non-null  int64 \n",
      " 31  FK Accuracy       18979 non-null  int64 \n",
      " 32  Long Passing      18979 non-null  int64 \n",
      " 33  Ball Control      18979 non-null  int64 \n",
      " 34  Movement          18979 non-null  int64 \n",
      " 35  Acceleration      18979 non-null  int64 \n",
      " 36  Sprint Speed      18979 non-null  int64 \n",
      " 37  Agility           18979 non-null  int64 \n",
      " 38  Reactions         18979 non-null  int64 \n",
      " 39  Balance           18979 non-null  int64 \n",
      " 40  Power             18979 non-null  int64 \n",
      " 41  Shot Power        18979 non-null  int64 \n",
      " 42  Jumping           18979 non-null  int64 \n",
      " 43  Stamina           18979 non-null  int64 \n",
      " 44  Strength          18979 non-null  int64 \n",
      " 45  Long Shots        18979 non-null  int64 \n",
      " 46  Mentality         18979 non-null  int64 \n",
      " 47  Aggression        18979 non-null  int64 \n",
      " 48  Interceptions     18979 non-null  int64 \n",
      " 49  Positioning       18979 non-null  int64 \n",
      " 50  Vision            18979 non-null  int64 \n",
      " 51  Penalties         18979 non-null  int64 \n",
      " 52  Composure         18979 non-null  int64 \n",
      " 53  Defending         18979 non-null  int64 \n",
      " 54  Marking           18979 non-null  int64 \n",
      " 55  Standing Tackle   18979 non-null  int64 \n",
      " 56  Sliding Tackle    18979 non-null  int64 \n",
      " 57  Goalkeeping       18979 non-null  int64 \n",
      " 58  GK Diving         18979 non-null  int64 \n",
      " 59  GK Handling       18979 non-null  int64 \n",
      " 60  GK Kicking        18979 non-null  int64 \n",
      " 61  GK Positioning    18979 non-null  int64 \n",
      " 62  GK Reflexes       18979 non-null  int64 \n",
      " 63  Total Stats       18979 non-null  int64 \n",
      " 64  Base Stats        18979 non-null  int64 \n",
      " 65  W/F               18979 non-null  object\n",
      " 66  SM                18979 non-null  object\n",
      " 67  A/W               18979 non-null  object\n",
      " 68  D/W               18979 non-null  object\n",
      " 69  IR                18979 non-null  object\n",
      " 70  PAC               18979 non-null  int64 \n",
      " 71  SHO               18979 non-null  int64 \n",
      " 72  PAS               18979 non-null  int64 \n",
      " 73  DRI               18979 non-null  int64 \n",
      " 74  DEF               18979 non-null  int64 \n",
      " 75  PHY               18979 non-null  int64 \n",
      " 76  Hits              16384 non-null  object\n",
      "dtypes: int64(54), object(23)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# looking for the dataframe\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53273983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>↓OVA</th>\n",
       "      <th>POT</th>\n",
       "      <th>BOV</th>\n",
       "      <th>Attacking</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>Finishing</th>\n",
       "      <th>Heading Accuracy</th>\n",
       "      <th>Short Passing</th>\n",
       "      <th>...</th>\n",
       "      <th>GK Positioning</th>\n",
       "      <th>GK Reflexes</th>\n",
       "      <th>Total Stats</th>\n",
       "      <th>Base Stats</th>\n",
       "      <th>PAC</th>\n",
       "      <th>SHO</th>\n",
       "      <th>PAS</th>\n",
       "      <th>DRI</th>\n",
       "      <th>DEF</th>\n",
       "      <th>PHY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "      <td>18979.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>226403.384794</td>\n",
       "      <td>25.194109</td>\n",
       "      <td>65.718636</td>\n",
       "      <td>71.136414</td>\n",
       "      <td>66.751726</td>\n",
       "      <td>248.938142</td>\n",
       "      <td>49.688392</td>\n",
       "      <td>45.842405</td>\n",
       "      <td>51.942726</td>\n",
       "      <td>58.768112</td>\n",
       "      <td>...</td>\n",
       "      <td>16.217187</td>\n",
       "      <td>16.519627</td>\n",
       "      <td>1595.286949</td>\n",
       "      <td>355.702197</td>\n",
       "      <td>67.453975</td>\n",
       "      <td>53.457031</td>\n",
       "      <td>57.681016</td>\n",
       "      <td>62.875020</td>\n",
       "      <td>49.866221</td>\n",
       "      <td>64.368934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27141.054157</td>\n",
       "      <td>4.710520</td>\n",
       "      <td>6.968999</td>\n",
       "      <td>6.114635</td>\n",
       "      <td>6.747193</td>\n",
       "      <td>74.299428</td>\n",
       "      <td>18.131153</td>\n",
       "      <td>19.567081</td>\n",
       "      <td>17.294409</td>\n",
       "      <td>14.519106</td>\n",
       "      <td>...</td>\n",
       "      <td>17.002239</td>\n",
       "      <td>17.854079</td>\n",
       "      <td>269.874789</td>\n",
       "      <td>40.761117</td>\n",
       "      <td>10.677859</td>\n",
       "      <td>13.827425</td>\n",
       "      <td>10.081857</td>\n",
       "      <td>9.927415</td>\n",
       "      <td>16.443213</td>\n",
       "      <td>9.601883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>210135.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>232418.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1627.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>246922.500000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>259216.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           Age          ↓OVA           POT           BOV  \\\n",
       "count   18979.000000  18979.000000  18979.000000  18979.000000  18979.000000   \n",
       "mean   226403.384794     25.194109     65.718636     71.136414     66.751726   \n",
       "std     27141.054157      4.710520      6.968999      6.114635      6.747193   \n",
       "min        41.000000     16.000000     47.000000     47.000000     48.000000   \n",
       "25%    210135.000000     21.000000     61.000000     67.000000     62.000000   \n",
       "50%    232418.000000     25.000000     66.000000     71.000000     67.000000   \n",
       "75%    246922.500000     29.000000     70.000000     75.000000     71.000000   \n",
       "max    259216.000000     53.000000     93.000000     95.000000     93.000000   \n",
       "\n",
       "          Attacking      Crossing     Finishing  Heading Accuracy  \\\n",
       "count  18979.000000  18979.000000  18979.000000      18979.000000   \n",
       "mean     248.938142     49.688392     45.842405         51.942726   \n",
       "std       74.299428     18.131153     19.567081         17.294409   \n",
       "min       42.000000      6.000000      3.000000          5.000000   \n",
       "25%      222.000000     38.000000     30.000000         44.000000   \n",
       "50%      263.000000     54.000000     49.000000         55.000000   \n",
       "75%      297.000000     63.000000     62.000000         64.000000   \n",
       "max      437.000000     94.000000     95.000000         93.000000   \n",
       "\n",
       "       Short Passing  ...  GK Positioning   GK Reflexes   Total Stats  \\\n",
       "count   18979.000000  ...    18979.000000  18979.000000  18979.000000   \n",
       "mean       58.768112  ...       16.217187     16.519627   1595.286949   \n",
       "std        14.519106  ...       17.002239     17.854079    269.874789   \n",
       "min         7.000000  ...        2.000000      2.000000    747.000000   \n",
       "25%        54.000000  ...        8.000000      8.000000   1452.000000   \n",
       "50%        62.000000  ...       11.000000     11.000000   1627.000000   \n",
       "75%        68.000000  ...       14.000000     14.000000   1781.000000   \n",
       "max        94.000000  ...       91.000000     90.000000   2316.000000   \n",
       "\n",
       "         Base Stats           PAC           SHO           PAS           DRI  \\\n",
       "count  18979.000000  18979.000000  18979.000000  18979.000000  18979.000000   \n",
       "mean     355.702197     67.453975     53.457031     57.681016     62.875020   \n",
       "std       40.761117     10.677859     13.827425     10.081857      9.927415   \n",
       "min      232.000000     25.000000     16.000000     25.000000     25.000000   \n",
       "25%      327.000000     61.000000     44.000000     51.000000     57.000000   \n",
       "50%      356.000000     68.000000     56.000000     58.000000     64.000000   \n",
       "75%      384.000000     75.000000     64.000000     64.000000     69.000000   \n",
       "max      498.000000     96.000000     93.000000     93.000000     95.000000   \n",
       "\n",
       "                DEF           PHY  \n",
       "count  18979.000000  18979.000000  \n",
       "mean      49.866221     64.368934  \n",
       "std       16.443213      9.601883  \n",
       "min       12.000000     28.000000  \n",
       "25%       35.000000     58.000000  \n",
       "50%       53.000000     65.000000  \n",
       "75%       63.000000     71.000000  \n",
       "max       91.000000     91.000000  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afba6a2",
   "metadata": {},
   "source": [
    "## Checking for null values:\n",
    "<a id='Null'></a>\n",
    "Checking the number of null or NaN (Not a Number) values in a dataset is an essential practice in data cleaning. It allows us to identify and understand the quality and completeness of our data. By examining the null or NaN values, we can gain insights into missing or incomplete information within the dataset. \n",
    "\n",
    "By knowing the number of null or NaN values, we can take appropriate actions to handle them. We can choose to remove or impute missing values, based on the context and nature of the data. This helps in maintaining the integrity and consistency of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847293d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                      0\n",
       "Name                    0\n",
       "LongName                0\n",
       "photoUrl                0\n",
       "playerUrl               0\n",
       "Nationality             0\n",
       "Age                     0\n",
       "↓OVA                    0\n",
       "POT                     0\n",
       "Club                    0\n",
       "Contract                0\n",
       "Positions               0\n",
       "Height                  0\n",
       "Weight                  0\n",
       "Preferred Foot          0\n",
       "BOV                     0\n",
       "Best Position           0\n",
       "Joined                  0\n",
       "Loan Date End       17966\n",
       "Value                   0\n",
       "Wage                    0\n",
       "Release Clause          0\n",
       "Attacking               0\n",
       "Crossing                0\n",
       "Finishing               0\n",
       "Heading Accuracy        0\n",
       "Short Passing           0\n",
       "Volleys                 0\n",
       "Skill                   0\n",
       "Dribbling               0\n",
       "Curve                   0\n",
       "FK Accuracy             0\n",
       "Long Passing            0\n",
       "Ball Control            0\n",
       "Movement                0\n",
       "Acceleration            0\n",
       "Sprint Speed            0\n",
       "Agility                 0\n",
       "Reactions               0\n",
       "Balance                 0\n",
       "Power                   0\n",
       "Shot Power              0\n",
       "Jumping                 0\n",
       "Stamina                 0\n",
       "Strength                0\n",
       "Long Shots              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isnull().sum().head(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1028a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aggression            0\n",
       "Interceptions         0\n",
       "Positioning           0\n",
       "Vision                0\n",
       "Penalties             0\n",
       "Composure             0\n",
       "Defending             0\n",
       "Marking               0\n",
       "Standing Tackle       0\n",
       "Sliding Tackle        0\n",
       "Goalkeeping           0\n",
       "GK Diving             0\n",
       "GK Handling           0\n",
       "GK Kicking            0\n",
       "GK Positioning        0\n",
       "GK Reflexes           0\n",
       "Total Stats           0\n",
       "Base Stats            0\n",
       "W/F                   0\n",
       "SM                    0\n",
       "A/W                   0\n",
       "D/W                   0\n",
       "IR                    0\n",
       "PAC                   0\n",
       "SHO                   0\n",
       "PAS                   0\n",
       "DRI                   0\n",
       "DEF                   0\n",
       "PHY                   0\n",
       "Hits               2595\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isnull().sum().tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768218c",
   "metadata": {},
   "source": [
    "We can notice that we have a huge number of null values in the column named Loan Date End something around 17000+ but we can not drop the column on this basis only as the column contains necessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "771f2cbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    http://sofifa.com/player/158023/lionel-messi/2...\n",
       "1    http://sofifa.com/player/20801/c-ronaldo-dos-s...\n",
       "2    http://sofifa.com/player/200389/jan-oblak/210006/\n",
       "3    http://sofifa.com/player/192985/kevin-de-bruyn...\n",
       "4    http://sofifa.com/player/190871/neymar-da-silv...\n",
       "Name: playerUrl, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['playerUrl'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b7f8732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://cdn.sofifa.com/players/158/023/21_60.png\n",
       "1    https://cdn.sofifa.com/players/020/801/21_60.png\n",
       "2    https://cdn.sofifa.com/players/200/389/21_60.png\n",
       "3    https://cdn.sofifa.com/players/192/985/21_60.png\n",
       "4    https://cdn.sofifa.com/players/190/871/21_60.png\n",
       "Name: photoUrl, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['photoUrl'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b094576a",
   "metadata": {},
   "source": [
    "By looking over this data we can say that they are no use for us in this project as we can not analyse the url links so we can drop these columns their is no loss in this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f4def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df.drop(columns=['photoUrl', 'playerUrl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948884dc",
   "metadata": {},
   "source": [
    "## Removing special characters:\n",
    "<a id='special'></a>\n",
    "Removing special characters and extra spaces from a dataset is a crucial step in data preprocessing. It helps to ensure data cleanliness, consistency, and improves the quality of subsequent analysis. Special characters, such as punctuation marks or symbols, also extra spaces may not be relevant to the analysis or modeling process. They can introduce noise and unwanted variations in the data. By removing them, we can focus on the essential information within the dataset.\n",
    "\n",
    "By looking over the data we found that in some columns **.** and **,** are important so we will not remove these but also we have **...** which is of no use so we will remove that.\n",
    "\n",
    "We will use a python module named **re** to recognize pattern and replace the special characters with nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c7433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# replacing special characters except . and ,\n",
    "raw_df = raw_df.replace(r'[^a-zA-Z0-9.,]', '', regex=True)\n",
    "\n",
    "# replacing extra spaces\n",
    "raw_df = raw_df.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# replacing 3 cosicutive...\n",
    "raw_df = raw_df.replace(r'\\.{3}', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676161af",
   "metadata": {},
   "source": [
    "- r'[^a-zA-Z0-9.,]' matches any non-alphanumeric character and other than **.** and **,**. and replace() function replaces those with nothing so that they are removed.\n",
    "- r'\\s+' matches one or more whitespace characters. and replace() function replaces those with nothing so that they are removed.\n",
    "- r'\\.{3}' matches three consecutive periods. and replace() function replaces those with nothing so that they are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254bf8ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hits</th>\n",
       "      <th>Value</th>\n",
       "      <th>Wage</th>\n",
       "      <th>Release Clause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>771</td>\n",
       "      <td>103.5M</td>\n",
       "      <td>560K</td>\n",
       "      <td>138.4M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562</td>\n",
       "      <td>63M</td>\n",
       "      <td>220K</td>\n",
       "      <td>75.9M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>120M</td>\n",
       "      <td>125K</td>\n",
       "      <td>159.4M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207</td>\n",
       "      <td>129M</td>\n",
       "      <td>370K</td>\n",
       "      <td>161M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595</td>\n",
       "      <td>132M</td>\n",
       "      <td>270K</td>\n",
       "      <td>166.5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100K</td>\n",
       "      <td>1K</td>\n",
       "      <td>70K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>130K</td>\n",
       "      <td>500</td>\n",
       "      <td>165K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18976</th>\n",
       "      <td>NaN</td>\n",
       "      <td>120K</td>\n",
       "      <td>500</td>\n",
       "      <td>131K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18977</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100K</td>\n",
       "      <td>2K</td>\n",
       "      <td>88K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18978</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100K</td>\n",
       "      <td>1K</td>\n",
       "      <td>79K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18979 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hits   Value  Wage Release Clause\n",
       "0      771  103.5M  560K         138.4M\n",
       "1      562     63M  220K          75.9M\n",
       "2      150    120M  125K         159.4M\n",
       "3      207    129M  370K           161M\n",
       "4      595    132M  270K         166.5M\n",
       "...    ...     ...   ...            ...\n",
       "18974  NaN    100K    1K            70K\n",
       "18975  NaN    130K   500           165K\n",
       "18976  NaN    120K   500           131K\n",
       "18977  NaN    100K    2K            88K\n",
       "18978  NaN    100K    1K            79K\n",
       "\n",
       "[18979 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[['Hits','Value', 'Wage', 'Release Clause']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c75cff",
   "metadata": {},
   "source": [
    "## Changing data types & processing data\n",
    "<a id='k-m_to_int'></a>\n",
    "By looking over these columns we can understand why we needed the special character **.** as it denotes values like **1.6K** and **75.9M**.\n",
    "\n",
    "Now we need to convert these values into **16000** and **75900000** repectively, but to do so we need to convert the data type to string first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c88289f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will change the data to bitwise\n",
    "raw_df['Hits'] = raw_df['Hits'].astype('|S')\n",
    "raw_df['Value'] = raw_df['Value'].astype('|S')\n",
    "raw_df['Wage'] = raw_df['Wage'].astype('|S')\n",
    "raw_df['Release Clause'] = raw_df['Release Clause'].astype('|S')\n",
    "\n",
    "# this will decode the bitwise data to original string type\n",
    "raw_df['Hits']= raw_df['Hits'].str.decode('utf-8')\n",
    "raw_df['Value']= raw_df['Value'].str.decode('utf-8')\n",
    "raw_df['Wage']= raw_df['Wage'].str.decode('utf-8')\n",
    "raw_df['Release Clause']= raw_df['Release Clause'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77caeb72",
   "metadata": {},
   "source": [
    "After this we can iterate over the data also can apply string like functions and methods.\n",
    "\n",
    "now we are writing our logic to removed the suffix **K** and **M** to be multiplyed with **1000** and **1000000** respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f24831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function named Convert_to_numeric\n",
    "def convert_to_numeric(value):\n",
    "    \n",
    "    # check the case having K\n",
    "    if value[-1] == 'K':\n",
    "        value=value[:-1] # removing suffix K\n",
    "        value=float(value)*1000 # multiplying the value with 1000\n",
    "        return int(value) # returning as integer\n",
    "    \n",
    "    # checking the case having M\n",
    "    elif value[-1] == 'M':\n",
    "        value=value[:-1] # removing suffix M\n",
    "        value=float(value)*1000000 # multiplying the value with 1000000\n",
    "        return int(value) # returning as integer\n",
    "    \n",
    "    # checking the case with nan value\n",
    "    elif value == 'nan':\n",
    "        return 0 # returning 0\n",
    "    \n",
    "    # checking case with not suffic and not nan value\n",
    "    else:\n",
    "        return int(value) # returning the same value as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7055c6bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     771\n",
       "1     562\n",
       "2     150\n",
       "3     207\n",
       "4     595\n",
       "5     248\n",
       "6     246\n",
       "7     120\n",
       "8    1600\n",
       "9     130\n",
       "Name: Hits, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the function\n",
    "raw_df['Hits'] = raw_df['Hits'].apply(convert_to_numeric)\n",
    "raw_df['Hits'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8e7fc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    103500000\n",
       "1     63000000\n",
       "2    120000000\n",
       "3    129000000\n",
       "4    132000000\n",
       "5    111000000\n",
       "6    120500000\n",
       "7    102000000\n",
       "8    185500000\n",
       "9    110000000\n",
       "Name: Value, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the function\n",
    "raw_df['Value'] = raw_df['Value'].apply(convert_to_numeric)\n",
    "raw_df['Value'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1a736d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    560000\n",
       "1    220000\n",
       "2    125000\n",
       "3    370000\n",
       "4    270000\n",
       "5    240000\n",
       "6    250000\n",
       "7    160000\n",
       "8    160000\n",
       "9    260000\n",
       "Name: Wage, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the function\n",
    "raw_df['Wage'] = raw_df['Wage'].apply(convert_to_numeric)\n",
    "raw_df['Wage'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa12e27b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    138400000\n",
       "1     75900000\n",
       "2    159400000\n",
       "3    161000000\n",
       "4    166500000\n",
       "5    132000000\n",
       "6    144300000\n",
       "7    120300000\n",
       "8    203100000\n",
       "9    147700000\n",
       "Name: Release Clause, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the function\n",
    "raw_df['Release Clause'] = raw_df['Release Clause'].apply(convert_to_numeric)\n",
    "raw_df['Release Clause'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bd9261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18979 entries, 0 to 18978\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   Hits            18979 non-null  int64\n",
      " 1   Value           18979 non-null  int64\n",
      " 2   Wage            18979 non-null  int64\n",
      " 3   Release Clause  18979 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 593.2 KB\n"
     ]
    }
   ],
   "source": [
    "raw_df[['Hits', 'Value', 'Wage', 'Release Clause']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04712b64",
   "metadata": {},
   "source": [
    "Now as we can see we have succesfully changed the format and also correctly processed the data.\n",
    "and hence it is done now we will focus on labeled encoding if required.\n",
    "## Label encoding:\n",
    "<a id='label'></a>\n",
    "\"label code\" typically refers to a numerical or categorical representation assigned to a specific label or category within a dataset. It is often used when dealing with categorical variables.\n",
    "For example: in a dataset with a \"color\" variable containing labels like \"red,\" \"green,\" and \"blue,\" label codes may assign the values 0, 1, and 2 respectively to represent each category.\n",
    "\n",
    "Label encoding is a common technique used in data preprocessing to convert categorical data into numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2d082c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Right    14445\n",
       "Left      4534\n",
       "Name: Preferred Foot, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Preferred Foot'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472cd25",
   "metadata": {},
   "source": [
    "Here we can see the column **Preferred Foot** have only 2 value **Right & Left** so we can label encode it with **0 & 1** respectively.\n",
    "but before doing this we firstly need to convert the Data type of the column to Strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c083f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will change the data to bitwise\n",
    "raw_df['Preferred Foot'] = raw_df['Preferred Foot'].astype('|S')\n",
    "\n",
    "# this will decode the bitwise data to original string type\n",
    "raw_df['Preferred Foot'] = raw_df['Preferred Foot'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b92bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_preferred_foot = {'Right': 0, 'Left': 1}\n",
    "raw_df['Preferred Foot'] = raw_df['Preferred Foot'].map(mapping_preferred_foot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da64bd",
   "metadata": {},
   "source": [
    "We are creating a dictionery **mapping_preferred_foot** which contains the labels for **Preferred foot** column and then using the **map function** to map the values over the column and replace it with the respective label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d1abd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14445\n",
       "1     4534\n",
       "Name: Preferred Foot, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Preferred Foot'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea993f",
   "metadata": {},
   "source": [
    "As we can see this encoded the labels as **0 for Right and 1 for left**. Also the number of value are as same as before(14445 Rights and 4534 Lefts).\n",
    "\n",
    "Now lets look over other columns which have multiple attributed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfd15695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CB     3686\n",
       "ST     2680\n",
       "CAM    2299\n",
       "GK     2075\n",
       "RM     1611\n",
       "CDM    1445\n",
       "LB     1086\n",
       "RB     1079\n",
       "CM     1047\n",
       "LM      871\n",
       "RW      298\n",
       "RWB     277\n",
       "LWB     261\n",
       "LW      186\n",
       "CF       78\n",
       "Name: Best Position, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Best Position'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6991d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    12701\n",
       "High       5288\n",
       "Low         990\n",
       "Name: A/W, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['A/W'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1e4822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    13956\n",
       "High       3297\n",
       "Low        1726\n",
       "Name: D/W, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['D/W'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9549b",
   "metadata": {},
   "source": [
    "So by looking for the value counts of the above columns we can conclude the decision to do the label encoding as the distinct values are very less in number. But on the other hands the columns below can not be Label encoded as the simple reason behind this is many distinct values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e05519cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "England         1705\n",
       "Germany         1195\n",
       "Spain           1065\n",
       "France          1003\n",
       "Argentina        943\n",
       "                ... \n",
       "Malawi             1\n",
       "Rwanda             1\n",
       "SoTomPrncipe       1\n",
       "Aruba              1\n",
       "Indonesia          1\n",
       "Name: Nationality, Length: 164, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Nationality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ee48d",
   "metadata": {},
   "source": [
    "Converting the columns data type into string so that we can label encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de6dbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will change the data to bitwise\n",
    "raw_df['Best Position'] = raw_df['Best Position'].astype('|S')\n",
    "raw_df['A/W'] = raw_df['A/W'].astype('|S')\n",
    "raw_df['D/W'] = raw_df['D/W'].astype('|S')\n",
    "\n",
    "# this will decode the bitwise data to original string type\n",
    "raw_df['Best Position'] = raw_df['Best Position'].str.decode('utf-8')\n",
    "raw_df['A/W'] = raw_df['A/W'].str.decode('utf-8')\n",
    "raw_df['D/W'] = raw_df['D/W'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7d37cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_positions = {\n",
    "'CB': 0,\n",
    "'ST': 1,\n",
    "'CAM': 2,\n",
    "'GK': 3,\n",
    "'RM': 4,\n",
    "'CDM': 5,\n",
    "'LB': 6,\n",
    "'RB': 7,\n",
    "'CM': 8,\n",
    "'LM': 9,\n",
    "'RW': 10,\n",
    "'RWB': 11,\n",
    "'LWB': 12,\n",
    "'LW': 13,\n",
    "'CF': 14\n",
    "}\n",
    "raw_df['Best Position'] = raw_df['Best Position'].map(mapping_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333563d",
   "metadata": {},
   "source": [
    "Mapping all the destinct values and assining related label for them and using map function we have replaced all the values with the respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48e32fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3686\n",
       "1     2680\n",
       "2     2299\n",
       "3     2075\n",
       "4     1611\n",
       "5     1445\n",
       "6     1086\n",
       "7     1079\n",
       "8     1047\n",
       "9      871\n",
       "10     298\n",
       "11     277\n",
       "12     261\n",
       "13     186\n",
       "14      78\n",
       "Name: Best Position, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Best Position'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa31d9b",
   "metadata": {},
   "source": [
    "here we can see that we have converted the values of Best Position into label endoded data.\n",
    "But we also have a column named **Positions** ahving more than one position in a single value data. lets take a look over this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4a6dbc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RW,ST,CF\n",
       "1       ST,LW\n",
       "2          GK\n",
       "3      CAM,CM\n",
       "4      LW,CAM\n",
       "Name: Positions, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Positions'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88709b",
   "metadata": {},
   "source": [
    "So as you can see we have this type of data but we want the label encoded data so we will convert it into labels seprated with **,**. to do so we need to firstly convert it into sytring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40404ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df['Positions']=raw_df['Positions'].astype('|S')\n",
    "raw_df['Positions']=raw_df['Positions'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03c32a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['Positions'] = raw_df['Positions'].map(lambda x: ','.join(str(mapping_positions.get(p)) for p in x.split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3942cf9a",
   "metadata": {},
   "source": [
    "Here we used a **lambda function** to pass each value as **x** then use **split** to have a list of splited position on the basis of delimiter **,**. then used a for loop to pass the value to **map function** to map the value from **mapping_positions** we already created then just converting it into string and used **join** to rejoin the splited positions with **, and the labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b1704eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10,1,14\n",
       "1       1,13\n",
       "2          3\n",
       "3        2,8\n",
       "4       13,2\n",
       "Name: Positions, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Positions'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2777a4e",
   "metadata": {},
   "source": [
    "Here you can see the positions has been replaced with the respective labels.\n",
    "now we are labeling the columns **A/W and D/W** column, it is same as we did with the column **Best Position**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94fd630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_intencity = {'High': 0, 'Medium': 1, 'Low': 2}\n",
    "raw_df['A/W'] = raw_df['A/W'].map(mapping_intencity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99a75015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12701\n",
       "0     5288\n",
       "2      990\n",
       "Name: A/W, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['A/W'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4fca5",
   "metadata": {},
   "source": [
    "**A/W** column is successfully label encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f62bce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['D/W'] = raw_df['D/W'].map(mapping_intencity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5a8259b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13956\n",
       "0     3297\n",
       "2     1726\n",
       "Name: D/W, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['D/W'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cdf87c",
   "metadata": {},
   "source": [
    "So as we can see above we have succesfully label encoded the columns. <br>\n",
    "now we are converting some column data type into string and integer with respect to their values and use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55e24a",
   "metadata": {},
   "source": [
    "## Converting into right Data type\n",
    "<a id='Datatype'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c6a9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing Name column to string data type\n",
    "raw_df['Name']=raw_df['Name'].astype('|S')\n",
    "raw_df['Name']=raw_df['Name'].str.decode('utf-8')\n",
    "\n",
    "# changing LongName column to string data type\n",
    "raw_df['LongName']=raw_df['LongName'].astype('|S')\n",
    "raw_df['LongName']=raw_df['LongName'].str.decode('utf-8')\n",
    "\n",
    "# changing Nationality column to string data type\n",
    "raw_df['Nationality']=raw_df['Nationality'].astype('|S')\n",
    "raw_df['Nationality']=raw_df['Nationality'].str.decode('utf-8')\n",
    "\n",
    "# changing Club column to string data type\n",
    "raw_df['Club']=raw_df['Club'].astype('|S')\n",
    "raw_df['Club']=raw_df['Club'].str.decode('utf-8')\n",
    "\n",
    "# changing Weight column to string data type\n",
    "raw_df['Weight']=raw_df['Weight'].astype('|S')\n",
    "raw_df['Weight']=raw_df['Weight'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdba63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing W/F column to integer data type\n",
    "raw_df['W/F']=raw_df['W/F'].astype(int)\n",
    "\n",
    "# changing SM column to integer data type\n",
    "raw_df['SM']=raw_df['SM'].astype(int)\n",
    "\n",
    "# changing IR column to integer data type\n",
    "raw_df['IR']=raw_df['IR'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a1cf8",
   "metadata": {},
   "source": [
    "Lets see the Weight column what types of destinct values we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e18bb354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70kg      1495\n",
       "75kg      1457\n",
       "80kg      1108\n",
       "72kg      1022\n",
       "78kg       991\n",
       "          ... \n",
       "190lbs       1\n",
       "130lbs       1\n",
       "146lbs       1\n",
       "203lbs       1\n",
       "157lbs       1\n",
       "Name: Weight, Length: 79, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Weight'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e9190",
   "metadata": {},
   "source": [
    "As we can see that we have 2 types of values here **kg** one and **lbs**, but we want the values with kg only so we will write a function to convert the values into **kg** and then into integer.\n",
    "\n",
    "## Processing data to convert lbs into kg:\n",
    "<a id='Pounds_to_kg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffcde8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function named Convert_to_kg\n",
    "def convert_to_kg(value):\n",
    "    \n",
    "    # check the case having kg\n",
    "    if value[-1] == 'g':\n",
    "        value=value[:-2] # removing suffix kg\n",
    "        return int(value) # returning as integer\n",
    "    \n",
    "    # checking the case having lbs\n",
    "    elif value[-1] == 's':\n",
    "        value=value[:-3] # removing suffix lbs\n",
    "        value=float(value)*0.453592 # multiplying the value with 0.453592\n",
    "        return int(value) # returning as integer\n",
    "    \n",
    "    # checking the case with nan value\n",
    "    elif value == 'nan':\n",
    "        return 0 # returning 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b25dd444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets just use the function\n",
    "raw_df['Weight']=raw_df['Weight'].apply(convert_to_kg)\n",
    "\n",
    "# now we will change the column name as Weight_in_kg\n",
    "raw_df = raw_df.rename(columns={'Weight': 'Weight_in_kg'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085d2a07",
   "metadata": {},
   "source": [
    "After converting all values into kg and then integer we have changed the name of column as **Weight_in_kg**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6c45d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72\n",
       "1    83\n",
       "2    87\n",
       "3    70\n",
       "4    68\n",
       "Name: Weight_in_kg, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Weight_in_kg'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "645cbe63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18974    66\n",
       "18975    65\n",
       "18976    74\n",
       "18977    69\n",
       "18978    75\n",
       "Name: Weight_in_kg, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Weight_in_kg'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950588e4",
   "metadata": {},
   "source": [
    "So by looking over this wecan say we successfully processed the data.\n",
    "But in case of the column **Height** we can see a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7243104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18974    178cm\n",
       "18975    175cm\n",
       "18976    179cm\n",
       "18977    175cm\n",
       "18978    188cm\n",
       "Name: Height, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Height'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "863d435c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18974    178cm\n",
       "18975    175cm\n",
       "18976    179cm\n",
       "18977    175cm\n",
       "18978    188cm\n",
       "Name: Height, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df['Height'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531cdd23",
   "metadata": {},
   "source": [
    "Because we already removed the special character we also removed **'** and **\"** so to fix this we will drop the column and again take it from the **copy_df** data frame.\n",
    "\n",
    "## Droppping and using copy_df:\n",
    "<a id='use_copy'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1e17a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the column Height\n",
    "raw_df = raw_df.drop(columns='Height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39689236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the Column Height from copy_df with the name Height_in_cm\n",
    "raw_df['Height_in_cm'] = copy_df['Height']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3728257",
   "metadata": {},
   "source": [
    "We already coverted the name of the column as **Height_in_cm** as we want all the values in **cm**.\n",
    "Now we will write a function to split the **feet** and **inch** then convert it **cm** and then return as integer. <br>\n",
    "But first things first wwe need to convert the data type into string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8f1ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing Weight column to string data type\n",
    "raw_df['Height_in_cm']=raw_df['Height_in_cm'].astype('|S')\n",
    "raw_df['Height_in_cm']=raw_df['Height_in_cm'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f161c96",
   "metadata": {},
   "source": [
    "## Pocessing data to convert feet-inch into cm:\n",
    "<a id='feet-inch_to_cm'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c20f7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function named Convert_to_cm\n",
    "def convert_to_cm(value):\n",
    "    \n",
    "    # check the case having cm\n",
    "    if value[-1] == 'm':\n",
    "        value=value[:-2] # removing suffix cm\n",
    "        return int(value) # returning as integer\n",
    "    \n",
    "    # checking the case having \"\n",
    "    elif value[-1] == '\"':\n",
    "        value=value[:-1] # removing suffix \"\n",
    "        split_height = value.split(\"'\")\n",
    "        feet_in_cm=float(split_height[0])*30.48 # multiplying the feet value with 30.48 to convert into cm\n",
    "        inch_in_cm=float(split_height[1])*2.54 # multiplying the inch value with 2.54 to convert into cm\n",
    "        value=feet_in_cm+inch_in_cm\n",
    "        return int(value) # returning as integer\n",
    "    \n",
    "    # checking the case with nan value\n",
    "    elif value == 'nan':\n",
    "        return 0 # returning 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e54a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the function to convert all the values into cm\n",
    "raw_df['Height_in_cm']=raw_df['Height_in_cm'].apply(convert_to_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebea30ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18974    178\n",
       "18975    175\n",
       "18976    179\n",
       "18977    175\n",
       "18978    188\n",
       "Name: Height_in_cm, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Height_in_cm'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b748a",
   "metadata": {},
   "source": [
    "As we can see we have processed the data and converted all the values into **cm** and **integers**.\n",
    "Now we will take a look over the column named **Contract** just like the column **Height** we had made a mistake with this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b66a3651",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20042021\n",
       "1    20182022\n",
       "2    20142023\n",
       "3    20152023\n",
       "4    20172022\n",
       "Name: Contract, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Contract'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39b0be75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2004 ~ 2021\n",
       "1    2018 ~ 2022\n",
       "2    2014 ~ 2023\n",
       "3    2015 ~ 2023\n",
       "4    2017 ~ 2022\n",
       "Name: Contract, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df['Contract'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca794b",
   "metadata": {},
   "source": [
    "As we can see the differnce. deu to removing of special characters we also removed **~** and thus we made a mistake so for solving this we will drop this column and again take it from the copy data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efc4ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the column Contract from raw_df\n",
    "raw_df = raw_df.drop(columns=['Contract'])\n",
    "\n",
    "# coping the column Contract from copy_df\n",
    "raw_df['Contract'] = copy_df['Contract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5b3a485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2004 ~ 2021\n",
       "1    2018 ~ 2022\n",
       "2    2014 ~ 2023\n",
       "3    2015 ~ 2023\n",
       "4    2017 ~ 2022\n",
       "Name: Contract, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Contract'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e2a63",
   "metadata": {},
   "source": [
    "Now as we have the correct data we will convert it into strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96477bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing Contract column to string data type\n",
    "raw_df['Contract']=raw_df['Contract'].astype('|S')\n",
    "raw_df['Contract']=raw_df['Contract'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997e2ed",
   "metadata": {},
   "source": [
    "Okay after this lets take a look over the column **Joined** this tells the joining date of the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca5e188a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jul1,2004\n",
       "1    Jul10,2018\n",
       "2    Jul16,2014\n",
       "3    Aug30,2015\n",
       "4     Aug3,2017\n",
       "Name: Joined, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Joined'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d357c",
   "metadata": {},
   "source": [
    "As we can see the data type is not appropriate so we will convert it into **Datetime**.\n",
    "## Converting data type to datetime:\n",
    "<a id='Datetime'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9b9bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['Joined'] = raw_df['Joined'].apply(lambda x: pd.to_datetime(x, format='%b%d,%Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af622d",
   "metadata": {},
   "source": [
    "We used a **lambda function** and converted all the values into **Datetime** data type with the help of method named **to_datetime** in **pandas module**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e82b715c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2004-07-01\n",
       "1   2018-07-10\n",
       "2   2014-07-16\n",
       "3   2015-08-30\n",
       "4   2017-08-03\n",
       "Name: Joined, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Joined'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd41c42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 18979 entries, 0 to 18978\n",
      "Series name: Joined\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "18979 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 148.4 KB\n"
     ]
    }
   ],
   "source": [
    "raw_df['Joined'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9801363",
   "metadata": {},
   "source": [
    "But we do not want this we wanted to extract the date, month and year into seprate columns.\n",
    "## Extracting date, month & year into new column:\n",
    "<a id='extract'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2431d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['Joined_Date'] = raw_df['Joined'].dt.day\n",
    "raw_df['Joined_Month'] = raw_df['Joined'].dt.month\n",
    "raw_df['Joined_Year'] = raw_df['Joined'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df4d868",
   "metadata": {},
   "source": [
    "Here we have created columns named **Joined_Date**,**Joined_Month** and **Joined_Year** and extracted the date, month and year using the methods **dt.day**,**dt.month** and **dt.year** repectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4092d09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1    10\n",
       "2    16\n",
       "3    30\n",
       "4     3\n",
       "Name: Joined_Date, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Joined_Date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97224ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7\n",
       "1    7\n",
       "2    7\n",
       "3    8\n",
       "4    8\n",
       "Name: Joined_Month, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Joined_Month'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52ea8afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2004\n",
       "1    2018\n",
       "2    2014\n",
       "3    2015\n",
       "4    2017\n",
       "Name: Joined_Year, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Joined_Year'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cbf8e1",
   "metadata": {},
   "source": [
    "now as we can see we have the date, month and year of joining in saprated column we do not further need the column **Joined** so we will drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfc331bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df.drop(columns=['Joined'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ac739",
   "metadata": {},
   "source": [
    "Also changing the data type of **Loan Date End** column to **Datetime**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ac0acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['Loan Date End'] = raw_df['Loan Date End'].apply(lambda x: pd.to_datetime(x, format='%b%d,%Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598b8e1",
   "metadata": {},
   "source": [
    "Now lets look over the **raw_df** again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad504272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18979 entries, 0 to 18978\n",
      "Data columns (total 77 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   ID                18979 non-null  int64         \n",
      " 1   Name              18979 non-null  object        \n",
      " 2   LongName          18979 non-null  object        \n",
      " 3   Nationality       18979 non-null  object        \n",
      " 4   Age               18979 non-null  int64         \n",
      " 5   ↓OVA              18979 non-null  int64         \n",
      " 6   POT               18979 non-null  int64         \n",
      " 7   Club              18979 non-null  object        \n",
      " 8   Positions         18979 non-null  object        \n",
      " 9   Weight_in_kg      18979 non-null  int64         \n",
      " 10  Preferred Foot    18979 non-null  int64         \n",
      " 11  BOV               18979 non-null  int64         \n",
      " 12  Best Position     18979 non-null  int64         \n",
      " 13  Loan Date End     1013 non-null   datetime64[ns]\n",
      " 14  Value             18979 non-null  int64         \n",
      " 15  Wage              18979 non-null  int64         \n",
      " 16  Release Clause    18979 non-null  int64         \n",
      " 17  Attacking         18979 non-null  int64         \n",
      " 18  Crossing          18979 non-null  int64         \n",
      " 19  Finishing         18979 non-null  int64         \n",
      " 20  Heading Accuracy  18979 non-null  int64         \n",
      " 21  Short Passing     18979 non-null  int64         \n",
      " 22  Volleys           18979 non-null  int64         \n",
      " 23  Skill             18979 non-null  int64         \n",
      " 24  Dribbling         18979 non-null  int64         \n",
      " 25  Curve             18979 non-null  int64         \n",
      " 26  FK Accuracy       18979 non-null  int64         \n",
      " 27  Long Passing      18979 non-null  int64         \n",
      " 28  Ball Control      18979 non-null  int64         \n",
      " 29  Movement          18979 non-null  int64         \n",
      " 30  Acceleration      18979 non-null  int64         \n",
      " 31  Sprint Speed      18979 non-null  int64         \n",
      " 32  Agility           18979 non-null  int64         \n",
      " 33  Reactions         18979 non-null  int64         \n",
      " 34  Balance           18979 non-null  int64         \n",
      " 35  Power             18979 non-null  int64         \n",
      " 36  Shot Power        18979 non-null  int64         \n",
      " 37  Jumping           18979 non-null  int64         \n",
      " 38  Stamina           18979 non-null  int64         \n",
      " 39  Strength          18979 non-null  int64         \n",
      " 40  Long Shots        18979 non-null  int64         \n",
      " 41  Mentality         18979 non-null  int64         \n",
      " 42  Aggression        18979 non-null  int64         \n",
      " 43  Interceptions     18979 non-null  int64         \n",
      " 44  Positioning       18979 non-null  int64         \n",
      " 45  Vision            18979 non-null  int64         \n",
      " 46  Penalties         18979 non-null  int64         \n",
      " 47  Composure         18979 non-null  int64         \n",
      " 48  Defending         18979 non-null  int64         \n",
      " 49  Marking           18979 non-null  int64         \n",
      " 50  Standing Tackle   18979 non-null  int64         \n",
      " 51  Sliding Tackle    18979 non-null  int64         \n",
      " 52  Goalkeeping       18979 non-null  int64         \n",
      " 53  GK Diving         18979 non-null  int64         \n",
      " 54  GK Handling       18979 non-null  int64         \n",
      " 55  GK Kicking        18979 non-null  int64         \n",
      " 56  GK Positioning    18979 non-null  int64         \n",
      " 57  GK Reflexes       18979 non-null  int64         \n",
      " 58  Total Stats       18979 non-null  int64         \n",
      " 59  Base Stats        18979 non-null  int64         \n",
      " 60  W/F               18979 non-null  int32         \n",
      " 61  SM                18979 non-null  int32         \n",
      " 62  A/W               18979 non-null  int64         \n",
      " 63  D/W               18979 non-null  int64         \n",
      " 64  IR                18979 non-null  int32         \n",
      " 65  PAC               18979 non-null  int64         \n",
      " 66  SHO               18979 non-null  int64         \n",
      " 67  PAS               18979 non-null  int64         \n",
      " 68  DRI               18979 non-null  int64         \n",
      " 69  DEF               18979 non-null  int64         \n",
      " 70  PHY               18979 non-null  int64         \n",
      " 71  Hits              18979 non-null  int64         \n",
      " 72  Height_in_cm      18979 non-null  int64         \n",
      " 73  Contract          18979 non-null  object        \n",
      " 74  Joined_Date       18979 non-null  int64         \n",
      " 75  Joined_Month      18979 non-null  int64         \n",
      " 76  Joined_Year       18979 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int32(3), int64(67), object(6)\n",
      "memory usage: 10.9+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95722372",
   "metadata": {},
   "source": [
    "So we finally completed the data cleaning for the **raw_df**. <br> Also used the **copy_df** as we meesed up some columns like **Height** and **Contract**.\n",
    "\n",
    "Now lets create the **mapping data frame** we used to map the values in the process of **label encoding**, for future as we might forget the labels or for someone who will reffer this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34a1a16d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAM</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GK</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDM</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RB</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LM</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RWB</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LWB</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LW</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CF</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Position_Code\n",
       "CB               0\n",
       "ST               1\n",
       "CAM              2\n",
       "GK               3\n",
       "RM               4\n",
       "CDM              5\n",
       "LB               6\n",
       "RB               7\n",
       "CM               8\n",
       "LM               9\n",
       "RW              10\n",
       "RWB             11\n",
       "LWB             12\n",
       "LW              13\n",
       "CF              14"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Positions_df = pd.DataFrame.from_dict(mapping_positions, orient='index', columns=['Position_Code'])\n",
    "Positions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5f2cc",
   "metadata": {},
   "source": [
    "Here we have created a data frame named **Positions_df** we used the function **from_dict** to pass the dictionery and used the **orient='index'** so the index of the passed dictionery will be treated as index for this data frame and lastly we named the column containing label_code as **Position_Code**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22c531d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intencity_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        intencity_Code\n",
       "High                 0\n",
       "Medium               1\n",
       "Low                  2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Intencity_df = pd.DataFrame.from_dict(mapping_intencity, orient='index', columns=['intencity_Code'])\n",
    "Intencity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6b2dd4",
   "metadata": {},
   "source": [
    "Simillarly we have created another data frame named **Intencity_df** which contains the labels for columns **A/W & D/W**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1673b1",
   "metadata": {},
   "source": [
    "## Saving the cleaned data into csv files:\n",
    "<a id='save'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa4cb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the data as data.csv \n",
    "raw_.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c839f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the Intencity_df as Intencity_label.csv\n",
    "Intencity_df.to_csv('Intencity_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75c3c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the Positions_df as Positions_label.csv\n",
    "Positions_df.to_csv('Positions_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3dc58",
   "metadata": {},
   "source": [
    "We have used **to_csv** method to export the data frame as csv and used **index='False'** as we do not wanted to have index in our csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da6e59",
   "metadata": {},
   "source": [
    "# Closing the project:\n",
    "<a id='close'></a>\n",
    "In my data cleaning project, I utilized pandas to clean the Fifa 2021 dataset obtained from Kaggle. To ensure data integrity, I started by making a copy of the dataset, allowing me to revert any changes if needed. Throughout the cleaning process, I encountered several challenges with specific columns but successfully recovered the original data using the copied DataFrame.\n",
    "\n",
    "One of the key tasks involved transforming data types to their appropriate formats, ensuring consistency and accuracy. I also identified and dropped unnecessary columns, streamlining the dataset for further analysis. In addition, I extracted valuable information from the 'joined' column, creating new columns for the date, month, and year of joining.\n",
    "\n",
    "To enhance data analysis capabilities, I applied label encoding to convert categorical labels into numerical values. Furthermore, I performed data processing operations, such as converting weights from pounds to kilograms and heights from feet and inches to centimeters. I leveraged the re module to efficiently remove unwanted characters and ensure data cleanliness.\n",
    "\n",
    "Overall, this data cleaning project has been instrumental in preparing the Fifa 2021 dataset for advanced analysis and insights. The transformed and refined dataset now sets the stage for more comprehensive exploration and data-driven decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b6d18",
   "metadata": {},
   "source": [
    "# Acknoledgement:\n",
    "<a id='ack'></a>\n",
    "To all those who have followed this project, I sincerely hope that you have found it informative and engaging. Through this project, I aimed to not only clean and prepare the Fifa 2021 dataset but also inspire you to explore the world of data analysis and visualization further.\n",
    "\n",
    "I believe that this project has provided valuable insights into the data cleaning process and showcased the power of pandas in handling and transforming datasets.\n",
    "I encourage you to continue this project by conducting your own analysis and visualization. There is so much more to explore within the dataset, and by employing different analytical methods and visualization techniques, you can gain deeper insights and make meaningful discoveries.\n",
    "\n",
    "Once again, thank you for following this project and being a part of this learning journey."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
